{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMBFuQLRSgZJd8RT5kF31h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acsontfd/NewsScrapers/blob/main/assessment_CGT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install google-colab-selenium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yUuyRmM5DO9j",
        "outputId": "e4a2bfb4-f431-4f7d-e342-914f8fb5b97d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting google-colab-selenium\n",
            "  Downloading google_colab_selenium-1.0.14-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting selenium (from google-colab-selenium)\n",
            "  Downloading selenium-4.29.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium->google-colab-selenium)\n",
            "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium->google-colab-selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium->google-colab-selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->google-colab-selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google-colab-selenium) (0.14.0)\n",
            "Downloading google_colab_selenium-1.0.14-py3-none-any.whl (8.2 kB)\n",
            "Downloading selenium-4.29.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, trio, trio-websocket, selenium, google-colab-selenium\n",
            "Successfully installed google-colab-selenium-1.0.14 outcome-1.3.0.post0 selenium-4.29.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install google-colab-selenium[undetected]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NjyWlFDTEW6c",
        "outputId": "edae5e09-3abb-4bdf-8778-908b9c8c6814"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-colab-selenium[undetected] in /usr/local/lib/python3.11/dist-packages (1.0.14)\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (from google-colab-selenium[undetected]) (4.29.0)\n",
            "Collecting undetected-chromedriver (from google-colab-selenium[undetected])\n",
            "  Downloading undetected-chromedriver-3.5.5.tar.gz (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium[undetected]) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium[undetected]) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium[undetected]) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium[undetected]) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium[undetected]) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium->google-colab-selenium[undetected]) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from undetected-chromedriver->google-colab-selenium[undetected]) (2.32.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from undetected-chromedriver->google-colab-selenium[undetected]) (14.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium->google-colab-selenium[undetected]) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium->google-colab-selenium[undetected]) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium->google-colab-selenium[undetected]) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->undetected-chromedriver->google-colab-selenium[undetected]) (3.4.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->google-colab-selenium[undetected]) (0.14.0)\n",
            "Building wheels for collected packages: undetected-chromedriver\n",
            "  Building wheel for undetected-chromedriver (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for undetected-chromedriver: filename=undetected_chromedriver-3.5.5-py3-none-any.whl size=47048 sha256=1838aae7e868ae6e910c58e4c24eb10ba48e4be5a1ad75b82ce698928aa910e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/b9/03/4b6e38f019d6170e8c25df2e1e362d7bdf9ff4012df2dc85c0\n",
            "Successfully built undetected-chromedriver\n",
            "Installing collected packages: undetected-chromedriver\n",
            "Successfully installed undetected-chromedriver-3.5.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install selenium webdriver-manager"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIPlHKyRfD3n",
        "outputId": "22845aff-3040-4470-ebb9-473632032f3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.29.0)\n",
            "Collecting webdriver-manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.29.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Collecting python-dotenv (from webdriver-manager)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (24.2)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv, webdriver-manager\n",
            "Successfully installed python-dotenv-1.0.1 webdriver-manager-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import requests\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from bs4 import BeautifulSoup\n",
        "import google_colab_selenium as gs\n",
        "from datetime import datetime, timedelta\n",
        "import re\n",
        "\n",
        "driver = gs.Chrome()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "JDwdJlJXDc1y",
        "outputId": "55e2ba7a-b2f3-4e01-97fa-e5898431e4a5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"193b2ea2-0b59-43de-8e2a-290ed3dfcf8f-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"193b2ea2-0b59-43de-8e2a-290ed3dfcf8f-text\">Updating and upgrading APT</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"193b2ea2-0b59-43de-8e2a-290ed3dfcf8f-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"193b2ea2-0b59-43de-8e2a-290ed3dfcf8f-text\");\n",
              "            text.innerText = \"Updated and upgraded APT\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"d2bbfc45-6ac8-4383-b398-120a37a62b5b-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"d2bbfc45-6ac8-4383-b398-120a37a62b5b-text\">Downloading Google Chrome</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"d2bbfc45-6ac8-4383-b398-120a37a62b5b-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"d2bbfc45-6ac8-4383-b398-120a37a62b5b-text\");\n",
              "            text.innerText = \"Downloaded Google Chrome\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"38547f60-0e73-417b-a4fe-15448bb801c7-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"38547f60-0e73-417b-a4fe-15448bb801c7-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"38547f60-0e73-417b-a4fe-15448bb801c7-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"38547f60-0e73-417b-a4fe-15448bb801c7-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert relative time (e.g. 4 mins ago)to actual date\n",
        "\n",
        "def get_published_date(relative_time):\n",
        "\n",
        "    now = datetime.now()\n",
        "\n",
        "    parts = relative_time.split()\n",
        "    if len(parts) < 2:\n",
        "        return now.strftime(\"%Y-%m-%d %H:%M\")  # Return current time if format is unknown\n",
        "\n",
        "    num, unit = int(parts[0]), parts[1]\n",
        "\n",
        "    # Convert different time formats\n",
        "    if \"minute\" in unit:\n",
        "        return (now - timedelta(minutes=num)).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    elif \"hour\" in unit:\n",
        "        return (now - timedelta(hours=num)).strftime(\"%Y-%m-%d %H:%M\")\n",
        "    elif \"day\" in unit:\n",
        "        return (now - timedelta(days=num)).strftime(\"%Y-%m-%d\")\n",
        "    elif \"week\" in unit:\n",
        "        return (now - timedelta(weeks=num)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    return now.strftime(\"%Y-%m-%d\")  # Default case"
      ],
      "metadata": {
        "id": "edcrtrh57a_i"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regex to check if the extracted text follows a valid date format\n",
        "def is_valid_date(date_text):\n",
        "    date_pattern = r\"^\\d{1,2} [A-Za-z]+( \\d{4})?$\"  # Matches \"11 Feb\", \"23 February\", or \"17 December 2024\"\n",
        "    return bool(re.match(date_pattern, date_text))"
      ],
      "metadata": {
        "id": "PYB6XQNTIZtb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "News Article Scraping"
      ],
      "metadata": {
        "id": "BJps9kbno_eK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def bbc_articles():\n",
        "    BASE_URL = 'https://www.bbc.com/news'\n",
        "    response = requests.get(BASE_URL)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve BBC news. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "    print(\"The response code is:\", response.status_code)\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract tab links\n",
        "    tabs = soup.select('nav a')  # Select all navigation links\n",
        "    tab_links = {tab.text.strip(): f\"https://www.bbc.com{tab['href']}\" for tab in tabs if tab.get('href') and '/news' in tab['href']}\n",
        "\n",
        "    articles_data = []\n",
        "\n",
        "    # Visit each tab and scrape articles\n",
        "    for category, url in tab_links.items():\n",
        "        print(f\"Scraping category: {category} - {url}\")\n",
        "        response = requests.get(url)\n",
        "        time.sleep(2)  # Prevent being blocked\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to retrieve {category} news.\")\n",
        "            continue\n",
        "\n",
        "        tab_soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        headlines = tab_soup.find_all(\"h2\", {\"data-testid\": \"card-headline\"})\n",
        "        descriptions = tab_soup.find_all(\"p\", {\"data-testid\": \"card-description\"})\n",
        "        published_dates = tab_soup.find_all(\"span\", {\"data-testid\": \"card-metadata-lastupdated\"})\n",
        "\n",
        "        for i in range(len(headlines)):\n",
        "            title = headlines[i].text.strip()\n",
        "            description = descriptions[i].text.strip() if i < len(descriptions) else \"No description\"\n",
        "            relative_time = published_dates[i].text.strip() if i < len(published_dates) else \"No date\"\n",
        "\n",
        "            articles_data.append({\n",
        "                \"published_date\": relative_time,  # Needs date parsing function\n",
        "                \"headline\": title,\n",
        "                \"publisher\": \"BBC\",\n",
        "                \"article_content\": description,\n",
        "                \"category\": category  # Assign the category dynamically\n",
        "            })\n",
        "\n",
        "    print(f\"Total BBC articles scraped: {len(articles_data)}\")\n",
        "    return articles_data\n",
        "\n",
        "# Run function\n",
        "bbc_news = bbc_articles()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxjEHxdlYQfz",
        "outputId": "6c2252b6-e7d4-44f4-e4c8-add82e4c3efb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The response code is: 200\n",
            "Scraping category: News - https://www.bbc.com/news\n",
            "Scraping category: Israel-Gaza War - https://www.bbc.com/news/topics/c2vdnvdg6xxt\n",
            "Scraping category: War in Ukraine - https://www.bbc.com/news/war-in-ukraine\n",
            "Scraping category: US & Canada - https://www.bbc.com/news/us-canada\n",
            "Scraping category: UK - https://www.bbc.com/news/uk\n",
            "Scraping category: Africa - https://www.bbc.com/news/world/africa\n",
            "Scraping category: Asia - https://www.bbc.com/news/world/asia\n",
            "Scraping category: Australia - https://www.bbc.com/news/world/australia\n",
            "Scraping category: Europe - https://www.bbc.com/news/world/europe\n",
            "Scraping category: Latin America - https://www.bbc.com/news/world/latin_america\n",
            "Scraping category: Middle East - https://www.bbc.com/news/world/middle_east\n",
            "Scraping category: In Pictures - https://www.bbc.com/news/in_pictures\n",
            "Scraping category: BBC InDepth - https://www.bbc.com/news/bbcindepth\n",
            "Scraping category: BBC Verify - https://www.bbc.com/news/bbcverify\n",
            "Total BBC articles scraped: 471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_bbc = pd.DataFrame(bbc_news)\n",
        "df_bbc.to_csv('bbc_news.csv', index=False)"
      ],
      "metadata": {
        "id": "DDHCEDlnq3LI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bbc_sports_articles():\n",
        "    URL = 'https://www.bbc.com/sport'\n",
        "    response = requests.get(URL)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"The response code is:\", response.status_code)\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        articles_data = []\n",
        "        headlines = soup.find_all(\"p\", class_=\"ssrcss-1b1mki6-PromoHeadline\")  # Extract headlines\n",
        "        descriptions = soup.find_all(\"p\", {\"data-testid\": \"card-description\"})\n",
        "        published_dates = soup.find_all(\"span\", class_=\"ssrcss-1f39n02-VisuallyHidden\")  # Extract actual date\n",
        "\n",
        "        for i in range(len(headlines)):\n",
        "            title = headlines[i].text.strip()\n",
        "            description = descriptions[i].text.strip() if i < len(descriptions) else \"No description\"\n",
        "            extracted_date = published_dates[i].text.strip() if i < len(published_dates) else \"No date\"\n",
        "\n",
        "            # Process extracted date\n",
        "            if \"ago\" in extracted_date:\n",
        "                published_date = get_published_date(extracted_date)  # Convert relative time\n",
        "            elif is_valid_date(extracted_date):\n",
        "                try:\n",
        "                    # Convert absolute date to YYYY-MM-DD if year is present\n",
        "                    if len(extracted_date.split()) == 3:\n",
        "                        published_date = datetime.strptime(extracted_date, \"%d %B %Y\").strftime(\"%Y-%m-%d\")\n",
        "                    else:\n",
        "                        # Keep as-is for formats like \"23 February\"\n",
        "                        published_date = extracted_date\n",
        "                except ValueError:\n",
        "                    published_date = extracted_date  # If conversion fails, store as-is\n",
        "            else:\n",
        "                print(f\"Skipping invalid date: {extracted_date}\")\n",
        "                continue  # Skip if it's not a valid date\n",
        "\n",
        "            articles_data.append({\n",
        "                \"published_date\": published_date,\n",
        "                \"headline\": title,\n",
        "                \"publisher\": \"BBC\",\n",
        "                \"article_content\": description,\n",
        "                \"category\": \"Sports\"\n",
        "            })\n",
        "\n",
        "        print(f\"BBC Sports articles scraped: {len(articles_data)}\")\n",
        "        return articles_data\n",
        "    else:\n",
        "        print(f\"Failed to retrieve BBC Sports news. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "# Run function\n",
        "bbc_sports_news = bbc_sports_articles()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1PPCaDd9s6B",
        "outputId": "a2d5aefd-9079-4984-bd6b-93dc4aa20b66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The response code is: 200\n",
            "Skipping invalid date: BBC Homepage\n",
            "Skipping invalid date: More menu\n",
            "Skipping invalid date: More menu\n",
            "Skipping invalid date: Close menu\n",
            "Skipping invalid date: BBC Sport\n",
            "Skipping invalid date: Watch: YouTuber MrBeast crashes Formula E car. Video, 00:00:30\n",
            "Skipping invalid date: Uncle Harry is 'the best supporter ever' - Lampard. Video, 00:02:01\n",
            "Skipping invalid date: Mourinho falls asleep during reporter's long question. Video, 00:00:34\n",
            "Skipping invalid date: Chelsea must finish in top four - Colwill. Video, 00:04:03\n",
            "Skipping invalid date: 'Arriving in red will be cool' - Hamilton's Melbourne excitement. Video, 00:01:12\n",
            "Skipping invalid date: Russell won't 'bow down' to Verstappen. Video, 00:02:35\n",
            "Skipping invalid date: Ferguson 'not carried away after brilliant result' Video, 00:00:58\n",
            "Skipping invalid date: 'Liverpool must improve in PSG second leg' Video, 00:02:17\n",
            "Skipping invalid date: 'How on earth do you leave him out?' - the Kane debate. Video, 00:01:10\n",
            "Skipping invalid date: Jonas' trainer unhappy with 'uncalibrated' scales. Video, 00:01:17\n",
            "Skipping invalid date: Rugby Union Weekly. France win in Dublin to take control of Six Nations. Audio, 37 minutes\n",
            "Skipping invalid date: Football Daily. In Focus with Frank Lampard and Dion Dublin. Audio, 22 minutes\n",
            "BBC Sports articles scraped: 54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def bbc_business_articles():\n",
        "    URL = 'https://www.bbc.com/news/business'\n",
        "    response = requests.get(URL)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"The response code is:\", response.status_code)\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        articles_data = []\n",
        "        headlines = soup.find_all(\"h2\", {\"data-testid\": \"card-headline\"})\n",
        "        descriptions = soup.find_all(\"p\", {\"data-testid\": \"card-description\"})\n",
        "        published_dates = soup.find_all(\"span\", {\"data-testid\": \"card-metadata-lastupdated\"})\n",
        "\n",
        "        for i in range(len(headlines)):\n",
        "            title = headlines[i].text.strip()\n",
        "            description = descriptions[i].text.strip() if i < len(descriptions) else \"No description\"\n",
        "            relative_time = published_dates[i].text.strip() if i < len(published_dates) else \"No date\"\n",
        "\n",
        "            # Ensure relative_time is defined before using it\n",
        "            if \"ago\" in relative_time:\n",
        "                published_date = get_published_date(relative_time)\n",
        "            else:\n",
        "                published_date = relative_time  # Keep the original date if not relative\n",
        "\n",
        "            articles_data.append({\n",
        "                \"published_date\": published_date,\n",
        "                \"headline\": title,\n",
        "                \"publisher\": \"BBC\",\n",
        "                \"article_content\": description,\n",
        "                \"category\": \"Business\"\n",
        "            })\n",
        "\n",
        "        print(f\"BBC Business articles scraped: {len(articles_data)}\")\n",
        "        return articles_data\n",
        "    else:\n",
        "        print(f\"Failed to retrieve BBC Business news. Status code: {response.status_code}\")\n",
        "        return []\n",
        "\n",
        "# Run function\n",
        "bbc_business_news = bbc_business_articles()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9zLLW9XB3S2",
        "outputId": "8c7c92c4-345b-4ef1-e415-595ab96c719a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The response code is: 200\n",
            "BBC Business articles scraped: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_thestar_nation():\n",
        "    URL = \"https://www.thestar.com.my/news/nation\"\n",
        "\n",
        "    # Set up Selenium WebDriver\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # Use webdriver_manager to install ChromeDriver automatically\n",
        "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "    driver.get(URL)\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    max_clicks = 10\n",
        "    click_count = 0\n",
        "\n",
        "    while click_count < max_clicks:\n",
        "        try:\n",
        "            # Scroll down to make the \"Load More\" button visible\n",
        "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "            time.sleep(1.5)\n",
        "\n",
        "            # Find and click the \"Load More\" button\n",
        "            load_more_button = wait.until(EC.element_to_be_clickable((By.ID, \"loadMorestories\")))\n",
        "            driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
        "\n",
        "            click_count += 1\n",
        "            print(f\"Clicked Load More {click_count} time(s)...\")\n",
        "\n",
        "            # Wait for new articles to load\n",
        "            time.sleep(2)\n",
        "\n",
        "        except Exception:\n",
        "            print(\"No more articles to load or Load More button not found.\")\n",
        "            break  # Exit loop when no more articles\n",
        "\n",
        "    # Parse page source with BeautifulSoup\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "    articles_data = []\n",
        "    news_items = soup.find_all(\"div\", class_=\"row list-listing\")  # Each news item\n",
        "\n",
        "    for item in news_items:\n",
        "        # Extract headline\n",
        "        headline_tag = item.find(\"h2\", class_=\"f18\")\n",
        "        headline = headline_tag.a.text.strip() if headline_tag and headline_tag.a else \"No headline\"\n",
        "\n",
        "        # Extract description\n",
        "        description_tag = item.find(\"p\", style=\"overflow-wrap: break-word;\")\n",
        "        description = description_tag.text.strip() if description_tag else \"No description\"\n",
        "\n",
        "        # Extract timestamp\n",
        "        timestamp_tag = item.find(\"label\", class_=\"timestamp\")\n",
        "        published_date = timestamp_tag.text.strip() if timestamp_tag else \"No date\"\n",
        "\n",
        "        # Convert relative timestamps like \"7m ago\"\n",
        "        if \"ago\" in published_date:\n",
        "            published_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "        articles_data.append({\n",
        "            \"published_date\": published_date,\n",
        "            \"headline\": headline,\n",
        "            \"publisher\": \"The Star\",\n",
        "            \"article_content\": description,\n",
        "            \"category\": \"Nation\",\n",
        "        })\n",
        "\n",
        "    print(f\"Total articles scraped: {len(articles_data)}\")\n",
        "\n",
        "    # Close the browser\n",
        "    driver.quit()\n",
        "\n",
        "    return articles_data\n",
        "\n",
        "# Run scraper\n",
        "thestar_nation_news = scrape_thestar_nation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD1qrfUotW-r",
        "outputId": "89f246eb-9971-44ab-f78a-7a6cfbaa97ce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clicked Load More 1 time(s)...\n",
            "Clicked Load More 2 time(s)...\n",
            "Clicked Load More 3 time(s)...\n",
            "Clicked Load More 4 time(s)...\n",
            "Clicked Load More 5 time(s)...\n",
            "Clicked Load More 6 time(s)...\n",
            "Clicked Load More 7 time(s)...\n",
            "Clicked Load More 8 time(s)...\n",
            "Clicked Load More 9 time(s)...\n",
            "Clicked Load More 10 time(s)...\n",
            "Total articles scraped: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_thestar_business():\n",
        "    BASE_URL = \"https://www.thestar.com.my/news/latest?pgno={}&tag=Business#Latest\"\n",
        "\n",
        "    # Set up Selenium WebDriver\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")  # Run in headless mode (optional)\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "    max_pages = 8  # Scrape 8 pages\n",
        "    articles_data = []\n",
        "\n",
        "    for page_num in range(1, max_pages + 1):\n",
        "        current_url = BASE_URL.format(page_num)\n",
        "        print(f\"Scraping page {page_num}: {current_url}\")\n",
        "\n",
        "        driver.get(current_url)\n",
        "        time.sleep(5)  # Allow page to load\n",
        "\n",
        "        # Parse page source with BeautifulSoup\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "        news_items = soup.find_all(\"li\", class_=\"row\")  # Each news item\n",
        "\n",
        "        for item in news_items:\n",
        "            # Extract headline\n",
        "            headline_tag = item.find(\"h2\", class_=\"f18\")\n",
        "            headline = headline_tag.a.text.strip() if headline_tag and headline_tag.a else \"No headline\"\n",
        "\n",
        "            # Extract description\n",
        "            description_tag = item.find(\"p\", style=\"overflow-wrap: break-word;\")\n",
        "            description = description_tag.text.strip() if description_tag else \"No description\"\n",
        "\n",
        "            # Extract timestamp\n",
        "            timestamp_tag = item.find(\"time\", class_=\"timestamp\")\n",
        "            published_date = timestamp_tag.text.strip() if timestamp_tag else \"No date\"\n",
        "\n",
        "            # Convert relative timestamps like \"7m ago\"\n",
        "            if \"ago\" in published_date:\n",
        "                published_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            articles_data.append({\n",
        "                \"published_date\": published_date,\n",
        "                \"headline\": headline,\n",
        "                \"publisher\": \"The Star\",\n",
        "                \"article_content\": description,\n",
        "                \"category\": \"Business\",\n",
        "            })\n",
        "\n",
        "    print(f\"Total articles scraped: {len(articles_data)}\")\n",
        "\n",
        "    # Close the browser\n",
        "    driver.quit()\n",
        "\n",
        "    return articles_data\n",
        "\n",
        "# Run scraper\n",
        "thestar_business_news = scrape_thestar_business()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUy0zfOXCauG",
        "outputId": "2cce150f-faa4-4b84-e7bc-ba6d38fa1dfb"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping page 1: https://www.thestar.com.my/news/latest?pgno=1&tag=Business#Latest\n",
            "Scraping page 2: https://www.thestar.com.my/news/latest?pgno=2&tag=Business#Latest\n",
            "Scraping page 3: https://www.thestar.com.my/news/latest?pgno=3&tag=Business#Latest\n",
            "Scraping page 4: https://www.thestar.com.my/news/latest?pgno=4&tag=Business#Latest\n",
            "Scraping page 5: https://www.thestar.com.my/news/latest?pgno=5&tag=Business#Latest\n",
            "Scraping page 6: https://www.thestar.com.my/news/latest?pgno=6&tag=Business#Latest\n",
            "Scraping page 7: https://www.thestar.com.my/news/latest?pgno=7&tag=Business#Latest\n",
            "Scraping page 8: https://www.thestar.com.my/news/latest?pgno=8&tag=Business#Latest\n",
            "Total articles scraped: 160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_nst_nation():\n",
        "    BASE_URL = \"https://www.nst.com.my/news/nation\"\n",
        "    max_pages = 8  # Total pages to scrape\n",
        "    articles_data = []\n",
        "\n",
        "    # Set up Selenium WebDriver\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")  # Run in headless mode\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "\n",
        "    for page in range(1, max_pages + 1):\n",
        "        URL = f\"{BASE_URL}?page={page}\"\n",
        "        print(f\"Scraping: {URL}\")\n",
        "        driver.get(URL)\n",
        "        time.sleep(5)  # Allow time for JS to load\n",
        "\n",
        "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "\n",
        "        # Locate all news articles\n",
        "        news_items = soup.find_all(\"div\", class_=\"col\")\n",
        "\n",
        "        if not news_items:\n",
        "            print(\"No more articles found. Stopping.\")\n",
        "            break  # Stop if no articles are found\n",
        "\n",
        "        for item in news_items:\n",
        "            # Extract headline\n",
        "            headline_tag = item.find(\"h6\", class_=\"field-title\")\n",
        "            headline = headline_tag.text.strip() if headline_tag else \"No headline\"\n",
        "\n",
        "            # Extract description/snippet\n",
        "            description_tag = item.find(\"div\", class_=\"d-block article-teaser\")\n",
        "            description = description_tag.text.strip() if description_tag else \"No description\"\n",
        "\n",
        "            # Extract timestamp\n",
        "            timestamp_tag = item.find(\"span\", class_=\"created-ago\")\n",
        "            published_date = timestamp_tag.text.strip() if timestamp_tag else \"No date\"\n",
        "\n",
        "            # Convert relative timestamps like \"7m ago\"\n",
        "            if \"ago\" in published_date:\n",
        "                published_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            articles_data.append({\n",
        "                \"published_date\": published_date,\n",
        "                \"headline\": headline,\n",
        "                \"publisher\": \"NST\",\n",
        "                \"article_content\": description,\n",
        "                \"category\": \"Nation\",\n",
        "            })\n",
        "\n",
        "        print(f\"Total articles scraped so far: {len(articles_data)}\")\n",
        "\n",
        "    driver.quit()\n",
        "    return articles_data\n",
        "\n",
        "# Run scraper\n",
        "nst_nation_news = scrape_nst_nation()"
      ],
      "metadata": {
        "id": "XKOaHRN7Wxtx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d353b004-800b-450a-f616-26d73c7271f4"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping: https://www.nst.com.my/news/nation?page=1\n",
            "Total articles scraped so far: 21\n",
            "Scraping: https://www.nst.com.my/news/nation?page=2\n",
            "Total articles scraped so far: 42\n",
            "Scraping: https://www.nst.com.my/news/nation?page=3\n",
            "Total articles scraped so far: 63\n",
            "Scraping: https://www.nst.com.my/news/nation?page=4\n",
            "Total articles scraped so far: 84\n",
            "Scraping: https://www.nst.com.my/news/nation?page=5\n",
            "Total articles scraped so far: 105\n",
            "Scraping: https://www.nst.com.my/news/nation?page=6\n",
            "Total articles scraped so far: 126\n",
            "Scraping: https://www.nst.com.my/news/nation?page=7\n",
            "Total articles scraped so far: 147\n",
            "Scraping: https://www.nst.com.my/news/nation?page=8\n",
            "Total articles scraped so far: 168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_alj_news():\n",
        "    BASE_URL = \"https://www.aljazeera.com/news/\"\n",
        "\n",
        "    # Set up Selenium WebDriver\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")  # Run in headless mode\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    driver = gs.Chrome(options=options)\n",
        "    driver.get(BASE_URL)\n",
        "    time.sleep(3)  # Allow page to load\n",
        "\n",
        "    # Click \"Show More\" button 10 times\n",
        "    for i in range(10):\n",
        "        try:\n",
        "            show_more_button = driver.find_element(By.CLASS_NAME, \"show-more-button\")\n",
        "            driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
        "            time.sleep(5)  # Wait for content to load\n",
        "            print(f\"Clicked 'Show More' button {i + 1} times\")\n",
        "        except NoSuchElementException:\n",
        "            print(\"No 'Show More' button found. Exiting loop.\")\n",
        "            break\n",
        "\n",
        "    # Parse the page source\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "    driver.quit()\n",
        "\n",
        "    # Extract articles\n",
        "    articles = []\n",
        "    news_feed = soup.find(\"section\", id=\"news-feed-container\")\n",
        "    if news_feed:\n",
        "        news_items = news_feed.find_all(\"article\")\n",
        "        for item in news_items:\n",
        "            headline_tag = item.find(\"h3\", class_=\"gc__title\")\n",
        "            description_tag = item.find(\"p\")\n",
        "            date_tag = item.find(\"div\", class_=\"date-simple\")\n",
        "\n",
        "            published_date = date_tag.text.strip() if date_tag else \"No date\"\n",
        "            headline = headline_tag.text.strip() if headline_tag else \"No title\"\n",
        "            article_content = description_tag.text.strip() if description_tag else \"No content\"\n",
        "\n",
        "            articles.append({\n",
        "                \"published_date\": published_date,\n",
        "                \"headline\": headline,\n",
        "                \"publisher\": \"Al Jazeera\",\n",
        "                \"article_content\": article_content,\n",
        "                \"category\": \"General\",\n",
        "            })\n",
        "\n",
        "    print(f\"Total articles scraped: {len(articles)}\")\n",
        "    return articles\n",
        "\n",
        "# Run the scraper\n",
        "alj_news = scrape_alj_news()"
      ],
      "metadata": {
        "id": "WXwA1YLoTkH4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "1a819b72-9775-44b0-946a-47d3bd72d9a3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "            <div class=\"spinner-container\">\n",
              "                <div class=\"spinner\" id=\"db93a45c-7f29-43ad-a7eb-b458f5afb9cd-circle\"></div>\n",
              "                <div class=\"spinner-text\" id=\"db93a45c-7f29-43ad-a7eb-b458f5afb9cd-text\">Initializing Chromedriver</div>\n",
              "            </div>\n",
              "            <style>\n",
              "                @keyframes spin {\n",
              "                    from { transform: rotate(0deg); }\n",
              "                    to { transform: rotate(360deg); }\n",
              "                }\n",
              "\n",
              "                .spinner-container {\n",
              "                    display: flex;\n",
              "                    align-items: center;\n",
              "                    margin-bottom: 3px;\n",
              "                }\n",
              "\n",
              "                .spinner {\n",
              "                    border: 3px solid rgba(0, 0, 0, 0.1);\n",
              "                    border-left-color: lightblue;\n",
              "                    border-radius: 50%;\n",
              "                    width: 12px;\n",
              "                    height: 12px;\n",
              "                    animation: spin 1s linear infinite;\n",
              "                }\n",
              "\n",
              "                .spinner-text {\n",
              "                    padding-left: 6px;\n",
              "                }\n",
              "            </style>\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "            const element = document.getElementById(\"db93a45c-7f29-43ad-a7eb-b458f5afb9cd-circle\");\n",
              "            element.style.border = \"3px solid limegreen\";\n",
              "            element.style.animation = \"none\";\n",
              "\n",
              "            const text = document.getElementById(\"db93a45c-7f29-43ad-a7eb-b458f5afb9cd-text\");\n",
              "            text.innerText = \"Initialized Chromedriver\";\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clicked 'Show More' button 1 times\n",
            "Clicked 'Show More' button 2 times\n",
            "Clicked 'Show More' button 3 times\n",
            "Clicked 'Show More' button 4 times\n",
            "Clicked 'Show More' button 5 times\n",
            "Clicked 'Show More' button 6 times\n",
            "Clicked 'Show More' button 7 times\n",
            "Clicked 'Show More' button 8 times\n",
            "Clicked 'Show More' button 9 times\n",
            "Clicked 'Show More' button 10 times\n",
            "Total articles scraped: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_aljazeera_sports():\n",
        "    BASE_URL = \"https://www.aljazeera.com/sports/\"\n",
        "\n",
        "    # Set up Selenium WebDriver\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")  # Run in headless mode\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
        "    driver.get(BASE_URL)\n",
        "    time.sleep(3)  # Allow page to load\n",
        "\n",
        "    # Click \"Show More\" button 10 times\n",
        "    for i in range(10):\n",
        "        try:\n",
        "            show_more_button = driver.find_element(By.CLASS_NAME, \"show-more-button\")\n",
        "            driver.execute_script(\"arguments[0].click();\", show_more_button)\n",
        "            time.sleep(3)  # Wait for content to load\n",
        "            print(f\"Clicked 'Show More' button {i + 1} times\")\n",
        "        except NoSuchElementException:\n",
        "            print(\"No 'Show More' button found. Exiting loop.\")\n",
        "            break\n",
        "\n",
        "    # Parse the page source\n",
        "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
        "    driver.quit()\n",
        "\n",
        "    # Extract articles\n",
        "    articles = []\n",
        "    news_feed = soup.find(\"section\", id=\"news-feed-container\")\n",
        "    if news_feed:\n",
        "        news_items = news_feed.find_all(\"article\")\n",
        "        for item in news_items:\n",
        "            headline_tag = item.find(\"h3\", class_=\"gc__title\")\n",
        "            description_tag = item.find(\"p\")\n",
        "            date_tag = item.find(\"div\", class_=\"date-simple\")\n",
        "\n",
        "            published_date = date_tag.text.strip() if date_tag else \"No date\"\n",
        "            headline = headline_tag.text.strip() if headline_tag else \"No title\"\n",
        "            article_content = description_tag.text.strip() if description_tag else \"No content\"\n",
        "\n",
        "            articles.append({\n",
        "                \"published_date\": published_date,\n",
        "                \"headline\": headline,\n",
        "                \"publisher\": \"Al Jazeera\",\n",
        "                \"article_content\": article_content,\n",
        "                \"category\": \"Sports\",\n",
        "            })\n",
        "\n",
        "    print(f\"Total articles scraped: {len(articles)}\")\n",
        "    return articles\n",
        "\n",
        "# Run the scraper\n",
        "sports_news = scrape_aljazeera_sports()"
      ],
      "metadata": {
        "id": "aMSL7JV8vzPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6542b6eb-d13f-4603-bac9-fedb917084fe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clicked 'Show More' button 1 times\n",
            "Clicked 'Show More' button 2 times\n",
            "Clicked 'Show More' button 3 times\n",
            "Clicked 'Show More' button 4 times\n",
            "Clicked 'Show More' button 5 times\n",
            "Clicked 'Show More' button 6 times\n",
            "Clicked 'Show More' button 7 times\n",
            "Clicked 'Show More' button 8 times\n",
            "Clicked 'Show More' button 9 times\n",
            "Clicked 'Show More' button 10 times\n",
            "Total articles scraped: 110\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing"
      ],
      "metadata": {
        "id": "aNK59RwLocj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract and standardize date format\n",
        "def clean_date(published_date):\n",
        "    today = datetime.today()\n",
        "\n",
        "    # Convert relative dates like \"5 days ago\", \"4 hrs ago\", \"10 mins ago\"\n",
        "    relative_match = re.search(r\"(\\d+)\\s+(day|hour|hr|minute|min|second|sec)s?\\s+ago\", published_date, re.IGNORECASE)\n",
        "    if relative_match:\n",
        "        value, unit = int(relative_match.group(1)), relative_match.group(2).lower()\n",
        "        if unit in [\"day\", \"days\"]:\n",
        "            return (today - timedelta(days=value)).strftime(\"%Y-%m-%d\")\n",
        "        elif unit in [\"hour\", \"hr\", \"hours\", \"hrs\"]:\n",
        "            return (today - timedelta(hours=value)).strftime(\"%Y-%m-%d\")\n",
        "        elif unit in [\"minute\", \"min\", \"minutes\", \"mins\"]:\n",
        "            return (today - timedelta(minutes=value)).strftime(\"%Y-%m-%d\")\n",
        "        elif unit in [\"second\", \"sec\", \"seconds\", \"secs\"]:\n",
        "            return (today - timedelta(seconds=value)).strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Match standard date formats like \"8 Mar 2025\" or \"Mar 8, 2025 @ 9:50am\"\n",
        "    standard_match = re.search(r\"(\\d{1,2} \\w{3} \\d{4})|(\\w{3} \\d{1,2}, \\d{4})\", published_date)\n",
        "    if standard_match:\n",
        "        extracted_date = standard_match.group(0)\n",
        "        try:\n",
        "            if \",\" in extracted_date:  # Format like \"Mar 8, 2025\"\n",
        "                return datetime.strptime(extracted_date, \"%b %d, %Y\").strftime(\"%Y-%m-%d\")\n",
        "            else:  # Format like \"8 Mar 2025\"\n",
        "                return datetime.strptime(extracted_date, \"%d %b %Y\").strftime(\"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            return \"Invalid date\"\n",
        "\n",
        "    # Handle cases like \"11 February\" or \"March 5\" (without a year)\n",
        "    month_day_match = re.search(r\"(\\d{1,2}) (\\w+)\", published_date)\n",
        "    if month_day_match:\n",
        "        day, month = month_day_match.groups()\n",
        "        try:\n",
        "            parsed_date = datetime.strptime(f\"{day} {month} {today.year}\", \"%d %B %Y\")\n",
        "            if parsed_date > today:  # If date is in the future, assume last year\n",
        "                parsed_date = parsed_date.replace(year=today.year - 1)\n",
        "            return parsed_date.strftime(\"%Y-%m-%d\")\n",
        "        except ValueError:\n",
        "            return \"Invalid date\"\n",
        "\n",
        "    return published_date  # Return unchanged if no match found\n",
        "\n",
        "# Combine all scraped data into a DataFrame\n",
        "df_date = pd.DataFrame(\n",
        "    bbc_news\n",
        "    + bbc_sports_news\n",
        "    + bbc_business_news\n",
        "    + thestar_nation_news\n",
        "    + thestar_business_news\n",
        "    + nst_nation_news\n",
        "    + sports_news\n",
        "    + alj_news\n",
        ")\n",
        "\n",
        "# Apply function to clean 'published_date' column\n",
        "df_date[\"published_date\"] = df_date[\"published_date\"].apply(clean_date)\n",
        "\n",
        "# Display cleaned DataFrame\n",
        "print(df_date.head())\n",
        "\n",
        "# Save to CSV\n",
        "df_date.to_csv(\"news_date.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCI5b2l9kAQ8",
        "outputId": "ae240883-56bd-4a69-d4c3-0b81cf0ab2dc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  published_date                                           headline publisher  \\\n",
            "0     2025-03-09  Syrian security forces accused of killing hund...       BBC   \n",
            "1     2025-03-09  How Trump's threats have brought Canada's Libe...       BBC   \n",
            "2     2025-03-09  Migrant deported in chains: 'No-one will go to...       BBC   \n",
            "3     2025-03-09  Who is in the running to replace Trudeau as Li...       BBC   \n",
            "4     2025-03-09  Not so demure any more: The rise of 'free the ...       BBC   \n",
            "\n",
            "                                     article_content category  \n",
            "0  More than 700 civilians of the Alawite religio...     News  \n",
            "1  Justin Trudeau's party was headed for near-cer...     News  \n",
            "2  Indian deportee tells BBC about his risky jour...     News  \n",
            "3  The winner will be announced on Sunday - a for...     News  \n",
            "4  Stars like Charli XCX have made see-through ou...     News  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ge7UcYjdkkmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(bbc_news\n",
        "                      + bbc_sports_news\n",
        "                      + bbc_business_news\n",
        "                      + thestar_nation_news\n",
        "                      + thestar_business_news\n",
        "                      + nst_nation_news\n",
        "                      + sports_news\n",
        "                      + alj_news)\n",
        "\n",
        "# Save to CSV (optional)\n",
        "df.to_csv(\"news.csv\", index=False)\n",
        "\n",
        "# Display DataFrame\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "5IKeXkWOrDlL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "7bd313c6-9b95-41a9-827d-5fd8f9412bee"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1052, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  published_date                                           headline publisher  \\\n",
              "0      4 hrs ago  Syrian security forces accused of killing hund...       BBC   \n",
              "1       1 hr ago  How Trump's threats have brought Canada's Libe...       BBC   \n",
              "2      7 hrs ago  Migrant deported in chains: 'No-one will go to...       BBC   \n",
              "3      3 hrs ago  Who is in the running to replace Trudeau as Li...       BBC   \n",
              "4      7 hrs ago  Not so demure any more: The rise of 'free the ...       BBC   \n",
              "\n",
              "                                     article_content category  \n",
              "0  More than 700 civilians of the Alawite religio...     News  \n",
              "1  Justin Trudeau's party was headed for near-cer...     News  \n",
              "2  Indian deportee tells BBC about his risky jour...     News  \n",
              "3  The winner will be announced on Sunday - a for...     News  \n",
              "4  Stars like Charli XCX have made see-through ou...     News  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f09258df-011f-4ea6-8ab6-ae59b54eebbc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>published_date</th>\n",
              "      <th>headline</th>\n",
              "      <th>publisher</th>\n",
              "      <th>article_content</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4 hrs ago</td>\n",
              "      <td>Syrian security forces accused of killing hund...</td>\n",
              "      <td>BBC</td>\n",
              "      <td>More than 700 civilians of the Alawite religio...</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1 hr ago</td>\n",
              "      <td>How Trump's threats have brought Canada's Libe...</td>\n",
              "      <td>BBC</td>\n",
              "      <td>Justin Trudeau's party was headed for near-cer...</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7 hrs ago</td>\n",
              "      <td>Migrant deported in chains: 'No-one will go to...</td>\n",
              "      <td>BBC</td>\n",
              "      <td>Indian deportee tells BBC about his risky jour...</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3 hrs ago</td>\n",
              "      <td>Who is in the running to replace Trudeau as Li...</td>\n",
              "      <td>BBC</td>\n",
              "      <td>The winner will be announced on Sunday - a for...</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7 hrs ago</td>\n",
              "      <td>Not so demure any more: The rise of 'free the ...</td>\n",
              "      <td>BBC</td>\n",
              "      <td>Stars like Charli XCX have made see-through ou...</td>\n",
              "      <td>News</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f09258df-011f-4ea6-8ab6-ae59b54eebbc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f09258df-011f-4ea6-8ab6-ae59b54eebbc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f09258df-011f-4ea6-8ab6-ae59b54eebbc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e39fbfa3-e242-4ade-93ff-8439f6271a33\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e39fbfa3-e242-4ade-93ff-8439f6271a33')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e39fbfa3-e242-4ade-93ff-8439f6271a33 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1052,\n  \"fields\": [\n    {\n      \"column\": \"published_date\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 293,\n        \"samples\": [\n          \"2025-03-07\",\n          \"Mar 7, 2025 @ 6:25am\",\n          \"31 Jan 2025\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"headline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 846,\n        \"samples\": [\n          \"Injured Gazan boy takes first steps after surgery in Jordan\",\n          \"The 'Time Lords' racing to tackle the threat of GPS jamming\",\n          \"Pedro penalty snatches Brighton victory over Fulham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"publisher\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"The Star\",\n          \"Al Jazeera\",\n          \"BBC\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"article_content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 682,\n        \"samples\": [\n          \"A personal finance strategy popular among millennials is helping them to quit their job and retire decades early.\",\n          \"Once a close ally of President Yoon Suk-Yeol, Han tells the BBC how and why he turned against him.\",\n          \"The UAE has strongly rejected Sudan's allegations, calling the case a \\\"cynical publicity stunt.\\\"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"category\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 18,\n        \"samples\": [\n          \"News\",\n          \"Israel-Gaza War\",\n          \"Europe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ]
}